{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prov4ML InterTwinAI Logger Example\n",
    "\n",
    "This notebook is a simple example of how to use Prov4ML with the InterTwinAI logger interface and MNIST dataset. The task is simple digit classification using an MLP model. \n",
    "In this notebook the main functionalities of the logger are presented, while in a *normal* use case the logger would be automatically called by the InterTwinAI platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the necessary libraries and defining constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "import prov4ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATASETS = \"./data\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the logger and create context\n",
    "\n",
    "Initialize a new run within an experiment and start logging provenance data. \n",
    "This call specifies a user namespace, naming the experiment, defining the directory for saving provenance logs, and setting the logging frequency. \n",
    " - **prov_user_namespace**: The unique identifier for the user or organization, ensuring the provenance data is correctly attributed.\n",
    " - **experiment_name**: The name of the experiment, used to group related runs together.\n",
    " - **provenance_save_dir**: The directory where the provenance logs are stored.\n",
    " - **save_after_n_logs**: The interval for saving logs to file, to empty the variables saved in memory.\n",
    "\n",
    "The logger can be passed to the InterTwinAI workflow, which will automatically call the logger `create_logger_context` function. \n",
    "In this example, we will manually call the function to demonstrate the logger's functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = prov4ml.ProvMLItwinAILogger(\n",
    "    prov_user_namespace=\"www.example.org\",\n",
    "    experiment_name=\"experiment_name\",\n",
    "    provenance_save_dir=\"prov\",\n",
    "    save_after_n_logs=100,\n",
    ")\n",
    "logger.create_logger_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the model and dataset classes\n",
    "\n",
    "Prov4ml allows to log various metrics and parameters to ensure comprehensive tracking of the experiment’s provenance.\n",
    "In the same way, the dataset transformations, datasets and data loaders can be defined, and prov4ml allows logging of relevant information through the same `log` function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(28 * 28, 10), \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tform = transforms.Compose([\n",
    "    transforms.RandomRotation(10), \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "logger.log(item=tform, identifier=\"dataset transformation\", kind=prov4ml.LoggingItemKind.PARAMETER)\n",
    "\n",
    "train_ds = MNIST(PATH_DATASETS, train=True, download=True, transform=tform)\n",
    "test_ds = MNIST(PATH_DATASETS, train=False, download=True, transform=tform)\n",
    "train_ds = Subset(train_ds, range(BATCH_SIZE*4))\n",
    "test_ds = Subset(test_ds, range(BATCH_SIZE*2))\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "logger.log(item=train_loader, identifier=\"train_dataset\", kind=prov4ml.LoggingItemKind.PARAMETER)\n",
    "logger.log(item=test_loader, identifier=\"train_dataset\", kind=prov4ml.LoggingItemKind.PARAMETER)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model\n",
    "\n",
    "Train the MNIST model using PyTorch, then log the final model version using prov4ml, and evaluate the model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 29.77it/s]\n",
      "2it [00:00, 237.22it/s]\n"
     ]
    }
   ],
   "source": [
    "mnist_model = MNISTModel()\n",
    "\n",
    "optim = torch.optim.Adam(mnist_model.parameters(), lr=0.0002)\n",
    "logger.log(item=optim, identifier=\"optimizer\", kind=prov4ml.LoggingItemKind.PARAMETER)\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        optim.zero_grad()\n",
    "        y_hat = mnist_model(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        logger.log(item=loss.item(), identifier=\"MSE_train\", kind=prov4ml.LoggingItemKind.METRIC, context=prov4ml.Context.TRAINING, step=epoch)\n",
    "    \n",
    "    logger.log(item=epoch, identifier=\"epoch\", kind=prov4ml.LoggingItemKind.CARBON_METRIC, context=prov4ml.Context.TRAINING, step=epoch)\n",
    "    logger.log(item=epoch, identifier=\"epoch\", kind=prov4ml.LoggingItemKind.SYSTEM_METRIC, context=prov4ml.Context.TRAINING, step=epoch)\n",
    "    logger.log(item=mnist_model, identifier=f\"mnist_model_version_{epoch}\", kind=prov4ml.LoggingItemKind.MODEL_VERSION, context=prov4ml.Context.TRAINING, step=epoch)\n",
    "\n",
    "\n",
    "for i, (x, y) in tqdm(enumerate(test_loader)):\n",
    "    y_hat = mnist_model(x)\n",
    "    loss = F.cross_entropy(y_hat, y)\n",
    "    logger.log(item=loss.item(), identifier=\"MSE_test\", kind=prov4ml.LoggingItemKind.METRIC, context=prov4ml.Context.EVALUATION, step=epoch)\n",
    "\n",
    "logger.log(item=mnist_model, identifier=\"mnist_model_final\", kind=prov4ml.LoggingItemKind.FINAL_MODEL_VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Close the logger and save to ProvJSON\n",
    "\n",
    "Save the provenance data to a ProvJSON file for further analysis and visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any of the parent directories): .git\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Git not found, skipping commit hash retrieval\n"
     ]
    }
   ],
   "source": [
    "logger.destroy_logger_context()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
